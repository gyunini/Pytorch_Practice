{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPG3hrPD8pWuUpYmLDWnXyK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyunini/Pytorch_Practice/blob/main/3_Dataset_DataLoader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "gRlhU34VeAY_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmIdAEbvdmkU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, text, labels):\n",
        "    self.labels = labels\n",
        "    self.data = text\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, idx): # DataLoader에서 호출함\n",
        "    label = self.labels[idx]\n",
        "    text = self.data[idx]\n",
        "    sample= {'Text': text, 'Class': label}\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['Happy', 'Amazing', 'Sad', 'Unhappy', 'Glum']\n",
        "labels = ['Positive', 'Positive', 'Negative', 'Negative', 'Negative']\n",
        "MyDataset = CustomDataset(text, labels)"
      ],
      "metadata": {
        "id": "WPYCdmNweR_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(MyDataset) # iterable객체(호출하는 시점에 메모리로 올라감)이기 때문에 iter을 넣어주면 제너레이터 형태로 변환, next"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp8Gpe98fE_4",
        "outputId": "5317d44b-8222-4fd8-d82e-adbad4b90adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.CustomDataset"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "MyDataLoader = DataLoader(MyDataset, batch_size=2, shuffle=True)\n",
        "next(iter(MyDataLoader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL7hVTMQkius",
        "outputId": "558a952d-2e44-47f5-c5ed-c2ad0f726103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Text': ['Sad', 'Amazing'], 'Class': ['Negative', 'Positive']}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MyDataLoader = DataLoader(MyDataset, batch_size=2, shuffle=True)\n",
        "for dataset in MyDataLoader:\n",
        "  print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWsExPyClLAJ",
        "outputId": "48d9532f-2292-4e76-bc32-8ac1814c9df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Text': ['Unhappy', 'Sad'], 'Class': ['Negative', 'Negative']}\n",
            "{'Text': ['Happy', 'Glum'], 'Class': ['Positive', 'Negative']}\n",
            "{'Text': ['Amazing'], 'Class': ['Positive']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Dataset"
      ],
      "metadata": {
        "id": "51ASUJxtltle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import VisionDataset\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
        "import os\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "from skimage import io, transform\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "UXkE_sCTlr-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "\n",
        "class NotMNIST(VisionDataset):\n",
        "  resource_url = 'http://yaroslavvb.com/upload/notMNIST/notMNIST_large.tar.gz'\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      root: str,\n",
        "      train: bool = True,\n",
        "      transform: Optional[Callable] = None,\n",
        "      target_transform: Optional[Callable] = None,\n",
        "      download: bool = False,\n",
        "  ) -> None:\n",
        "      super(NotMNIST, self).__init__(root, transform=transform, target_transform=target_transform)\n",
        "      if not self._check_exists(): # 존재하지 않으면 다운로드\n",
        "        self.download()\n",
        "\n",
        "      if download:        # 유저가 직접 다운로드 할 수 있게 해줌\n",
        "        self.download() # 다운로드 이후 압축 해제함\n",
        "\n",
        "      self.data, self.targets = self._load_data() # 해당 path에서 데이터리스트를 만들어서 파일이름을 data, target을 label로 지정\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image_name = self.data[index] # 하나의 파일을 읽어서\n",
        "    image = io.imread(image_name)\n",
        "    label = self.targets[index]\n",
        "    if self.transform: # transform을 시켜서 보내줌\n",
        "      image = self.transform(image)\n",
        "    return image, label\n",
        "\n",
        "  def _load_data(self):\n",
        "    filepath = self.image_folder # 해당 폴더에서 - 이미지들이 폴더에 저장되어있음\n",
        "    data = []\n",
        "    targets = []\n",
        "\n",
        "    for target in os.listdir(filepath): # 데이터 리스트를 만듬\n",
        "      filenames = [os.path.abspath(\n",
        "          os.path.join(filepath, target, x)) for x in os.listdir(\n",
        "              os.path.join(filepath, target))]\n",
        "\n",
        "      targets.extend([target] * len(filenames)) # 타겟 설정\n",
        "      data.extend(filenames) # 파일name을 data에\n",
        "    return data, targets\n",
        "\n",
        "  @property\n",
        "  def raw_folder(self) -> str:\n",
        "    return os.path.join(self.root, self.__class__.__name__, 'raw')\n",
        "\n",
        "  @property\n",
        "  def image_folder(self) -> str:\n",
        "    return os.path.join(self.root, 'notMNIST_large')\n",
        "\n",
        "\n",
        "  def download(self) -> None:\n",
        "    os.makedirs(self.raw_folder, exist_ok=True)\n",
        "    fname = self.resource_url.split('/')[-1]\n",
        "    chunk_size = 1024\n",
        "\n",
        "    filesize = int(requests.head(self.resource_url).headers[\"Content-Length\"])\n",
        "    # filesize = 256*1024*1024\n",
        "    with requests.get(self.resource_url, stream=True) as r, open(\n",
        "        os.path.join(self.raw_folder, fname), 'wb') as f, tqdm(\n",
        "            unit='B', # unit string to be displayed\n",
        "            unit_scale=True, # let tqdm to determine the scale in kilo, mega, etc..\n",
        "            unit_divisor=1024, # is used when unit_scale is true\n",
        "            total=filesize, # the total iteration\n",
        "            file=sys.stdout, # default goes to stderr, this is the display on console\n",
        "            desc=fname # prefix to be displayed on progress bar\n",
        "        ) as progress:\n",
        "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "              # download the file chunk by chunk\n",
        "              datasize = f.write(chunk)\n",
        "              # on each chunk update the progress bar\n",
        "              progress.update(datasize)\n",
        "\n",
        "    self._extract_file(os.path.join(self.raw_folder, fname), target_path=self.root)\n",
        "\n",
        "\n",
        "\n",
        "  def _extract_file(self, fname, target_path) -> None:\n",
        "    if fname.endswith('tar.gz'):\n",
        "      tag = 'r:gz'\n",
        "    elif fname.endswith('tar'):\n",
        "      tag = 'r:'\n",
        "    tar = tarfile.open(fname, tag)\n",
        "    tar.extractall(path=target_path)\n",
        "    tar.close()\n",
        "\n",
        "\n",
        "  def _check_exists(self) -> bool:\n",
        "    return os.path.exists(self.raw_folder)"
      ],
      "metadata": {
        "id": "liQe0c_fmHwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = NotMNIST('data', download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "zIXWhx46THQY",
        "outputId": "18a2b4b1-ee90-4f07-9970-51958048338c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-ff11898d9642>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNotMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-95-1e1ce8559c9c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m        \u001b[0;31m# 유저가 직접 다운로드 할 수 있게 해줌\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 다운로드 이후 압축 해제함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 해당 path에서 데이터리스트를 만들어서 파일이름을 data, target을 label로 지정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-95-1e1ce8559c9c>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mchunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mfilesize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;31m# filesize = 256*1024*1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     with requests.get(self.resource_url, stream=True) as r, open(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/structures.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'content-length'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "for i in range(8):\n",
        "  sample = dataset[i]\n",
        "\n",
        "  ax = plt.subplot(1, 4, i + 1)\n",
        "  plt.tight_layout()\n",
        "  ax.set_title('Sample #{}'.format(i))\n",
        "  ax.axis('off')\n",
        "  plt.imshow(sample[0])\n",
        "\n",
        "  if i == 3:\n",
        "    plt.show()\n",
        "    break"
      ],
      "metadata": {
        "id": "JemuRGhkTSoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(), # 텐서로 변환\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = NotMNIST('data', download=False)\n",
        "\n",
        "dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "JvSSoV-YkmUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels = next(iter(dataset_loader))"
      ],
      "metadata": {
        "id": "EFXq8U1GlnKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features.shape # 128, 28, 28"
      ],
      "metadata": {
        "id": "AwbOmQuYlue0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}